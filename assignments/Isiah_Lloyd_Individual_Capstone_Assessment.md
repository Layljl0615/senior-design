## Individual Capstone Assessment
### Isiah Lloyd
---
 
Our senior design project is all about making the web more accessible to those with vision problems, also known as a "screen reader". Screen readers take the content that is on screen, and converts it using text to speech and allows the user to navigate without using a mouse. Screen readers on the market today expect websites to be marked up correctly using "ARIA" attributes, to be read in a coherent manner, yet many websites still don't take accessibility seriously. We hope to take matters into our own hands and allow our screen reader to parse websites that weren't designed to be accessible using artificial intelligence/machine learning. Another aspect of the screen reader is the interaction of a user between themselves and the computer. People with vision disabilities have a harder time hitting the button on a web page with a mouse, so the screen reader must find all the intractable content on the website and allow the user to interact using buttons or voice control.
 
My college experience will help guide me on the development of this project. There are plenty of classes I have taken at the University of Cincinnati that will help me develop this project. Most importantly, I think that what I learned in AI: Principles and Applications (CS 4033) will be my foundational experience for this project as it is my first, and only introduction to artificial intelligence. Other courses that will help me in this project are of course Data Structures (2028C) and  Design and Analysis of Algorithms (CS 4071). I am also currently taking Cloud Computing (CS 5165) and Requirements Engineering (CS 5217) which I think will help with the backend of this project and the managing of this project. I would also like to mention ACM@UC in this section because that's where I first learned Git and without that, collaboration would have been impossible for this project.  
 
I have had many co-ops during my time at UC. From being in the Strategic Student Program at Siemens PLM Software to being a Software Engineer Intern at Metarouter, all my co-ops had the same thing in common, web development. I believe my years working in the web development field will help me with this project because knowing how a website works from top to bottom is integral to making a AI understand how to describe one. I also think that the experiences at co-op helped tremendously with my soft skills, such as project management and collaboration. These will help with this project because we are the  ones responsible as a group to make sure we are on time with our deliverables. On my own I have also created projects using Web Extensions, I believe this is how we will ingest webpages and send them to our backend for processing.
 
I am excited about this project because accessibility of technology has always been an interest of mine. As more and more of our daily lives are moved online, we are creating more of a divide between people with disabilities being able to live a normal life. Larger companies are also getting more interested in accessibility. For example, Microsoft released the [Xbox Adaptive Controller](https://www.xbox.com/en-US/accessories/controllers/xbox-adaptive-controller), which allows people with physical disabilities to create the controller that fits their own situations and allows them to enjoy video games in comfort. For another example, more companies are getting worried about their accessibility of their websites because a landmark court decision has decided that the Americans with Disabilities Act also includes websites. This means if a website is discrementairy towards a person with disabilities they could be held liable. 
 
My preliminary plan for this project is to first discuss with a group on how they think websites should sound like to people who are blind. I thought of a fun activity of looking at some websites and individually writing up how we think how a screen reader should describe it, then take a popular screen reader such as JAWS and compare how a commercial screen reader sounds compared to how we think it should sound. Then I think we should take those scripts we wrote and try to figure out how we could use a computer to analyze a website and read out a script like that. This will require a good knowledge of the Document Object Model. I expect our results after this project is complete to sound very similar to the scripts we first wrote and also allow a person to interact with the website using their voice or buttons. In order to self-evaluate, I will use the requirements we decide at the beginning of this project and reflect how much I contributed to each of those requirements and if they are complete. 

